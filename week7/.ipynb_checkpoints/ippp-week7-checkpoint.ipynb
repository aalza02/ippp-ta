{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Internet and World Wide Web\n",
    "- The Internet is a physical network of cables and routers, and a set of protocols for moving information across that network.\n",
    "- The World Wide Web (WWW) is an information space on the Internet. It combines several concepts: \n",
    "    - Uniform Resource Locator (url) \n",
    "    - Hypertext Transfer Protocol (http) \n",
    "    - Hypertext Markup Language (html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Resource Locator\n",
    "- URLs are a system of globally unique identiﬁers for resources on the Web and elsewhere.\n",
    "- <code>scheme://host[:port]/path[?query][#fragment]</code>\n",
    "- scheme is a protcol such as http, https, etc. \n",
    "- host is something like google.com or localhost\n",
    "- :port is optional, allows a single host to have separate websites\n",
    "- path is the path to a particular resource like index.html \n",
    "- queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertext Transfer Protocol (HTTP)\n",
    "- HTTP is the core communications protocol for retrieving data \n",
    "- Consists of messages– requests and responses– sent between a client and a server\n",
    "\n",
    "![request_response](request_response.png)\n",
    "- HTTP Request\n",
    "\n",
    "![get_request](get_request.PNG)\n",
    "    - First line contains:\n",
    "        - HTTP method, here GET \n",
    "        - Requested URL \n",
    "        - HTTP version\n",
    "    - Rest of request may contain: \n",
    "        - User-Agent: description of the client (Used e.g. to determine whether to serve mobile website version)\n",
    "- HTTP Methods\n",
    "    - GET\n",
    "        - Most common method, used to get data\n",
    "    - POST \n",
    "        - Used to send data to server, e.g. form entries, search queries\n",
    "- HTTP Responses\n",
    "\n",
    "![response](response.PNG)\n",
    "    - First line contains:\n",
    "        - HTTP version\n",
    "        - HTTP response code\n",
    "    - Rest of response contains:\n",
    "        - Additional headers: Server, Content-Type, etc.\n",
    "        - Requested Content\n",
    "    - HTTP Response Codes\n",
    "        - 1xx: informational\n",
    "        - 2xx: Success\n",
    "            - 200: OK\n",
    "        - 3xx: Redirection\n",
    "            - 301: Redirect\n",
    "        - 4xx: Client Errors\n",
    "            - 404: File not found\n",
    "            - 403: Forbidden\n",
    "        - 5xx: Server Errors\n",
    "- HTTP GET Request Parameters\n",
    "\n",
    "![query](query.PNG)\n",
    "    - Query string with parameters sent in the URL of a GET request \n",
    "    - Parameter names and values are like a python dictionary\n",
    "    - Shouldn’t use with sensitive data (AUTH TOKEN etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertext Markup Language (HTML)\n",
    "   - [LEARN MORE ABOUT HTML](https://www.w3schools.com/html/html_intro.asp)\n",
    "   - Web browsers (Use Chrome) receive HTML documents from a web server or from local storage and render the documents into multimedia web pages. HTML describes the structure of a web page semantically and originally included cues for the appearance of the document.\n",
    "   - HTML sourcecode (View Page Source or Inspect)\n",
    "![html_source](html_source.PNG)\n",
    "    - HTML overview:\n",
    "        - HTML elements are the building blocks of HTML pages; HTML elements are represented by tags; HTML tags label pieces of content such as \"heading\", \"paragraph\", \"table\", and so on\n",
    "        - Most tags come in pairs (opening and closing):\n",
    "            - html\n",
    "            - div\n",
    "            - p \n",
    "            - a\n",
    "            - body\n",
    "        - Some do not (self-closing tags):\n",
    "            - img\n",
    "            - br\n",
    "        - Whitespace doesn't matter (unlike Python)\n",
    "    - Set up a basic HTML page in your text editor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Web Technologies\n",
    "- CSS\n",
    "    - .css files or code embedded in style tags\n",
    "- JavaScript\n",
    "    - .js files or code embedded in script tags\n",
    "    - browser uses the code to create dynamic content\n",
    "- Server-side languages\n",
    "    - Java, Ruby(on Rails), PHP, Python(Django), JavaScript(Node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Overview\n",
    "- Scraping is the process of programmatically extracting information from websites \n",
    "- Anything that you can view in a web browser can potentially be scraped\n",
    "- Reasons to Scrape:\n",
    "    - Some websites oﬀer services (APIs) that allow you to get data directly. So why scrape?\n",
    "        - Not all websites provide an API \n",
    "        - Not all of a website’s content is available through its API\n",
    "        - APIs often use tokens to limit the amount of data that can be requested (With scraping there is, in principle, no limit)\n",
    "- Note:\n",
    "    - Credit all sources \n",
    "        - Publishing scraped content can be a copyright violation \n",
    "    - Don’t overload websites\n",
    "        - Most sites will block you before you can do this\n",
    "    - You are not anonymous on the web\n",
    "        - Unless you take explicit steps (VPN, Tor, etc.) to do so\n",
    "    - Follow the rules of robots.txt\n",
    "- Common Web Resources:\n",
    "    - Google Maps\n",
    "    - OpenStreetMap\n",
    "    - Mapbox\n",
    "    - Twitter API\n",
    "    - American Community Survey\n",
    "    - Bureau of Labor Statistics\n",
    "    - Wikipedia tables\n",
    "    - Google Trends (No Need to Scrape)\n",
    "- Tools:\n",
    "    - [requests](https://2.python-requests.org/en/master/): Python module for retrieving web resources (mostly static) [tutorial](https://realpython.com/python-requests/#getting-started-with-requests)\n",
    "    - [beautifulsoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/): Python module for traversing and extracting elements from a web page.\n",
    "    - [pandas.read_html()](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.read_html.html): reads a well-formatted html table into a pandas DataFrame\n",
    "    - [selenium](https://selenium-python.readthedocs.io/): scrape JavaScript heavy pages with a web browser simulator\n",
    "    - [scrapy](https://docs.scrapy.org/en/latest/topics/selectors.html)\n",
    "    - regex: using the [re module](https://docs.python.org/3/library/re.html) to parse specific patterns; [good reference](https://www.tutorialspoint.com/python/python_reg_expressions.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read html tables\n",
    "import pandas as pd\n",
    "pd.read_html(\"https://en.wikipedia.org/wiki/Economy_of_China\", skiprows=2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Wikipedia Scrape Example:\n",
    "# # https://en.wikipedia.org//wiki/List_of_accidents_and_incidents_involving_commercial_aircraft\n",
    "# ################################################################################\n",
    "\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# # whether to import time based on whether initiate time.sleep()\n",
    "# # import time\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# base = 'https://en.wikipedia.org'\n",
    "# path = '/wiki/List_of_accidents_and_incidents_involving_commercial_aircraft'\n",
    "# response = requests.get(base + path)\n",
    "# page = bs(response.text, 'html.parser')\n",
    "# bolds = page.find_all('b')[:-1]\n",
    "# a_tags = page.find_all('a')\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# def get_table_data(one_accident_page, header_name):\n",
    "\n",
    "#     '''\n",
    "#     *This function takes as its argument an accident page and the name of\n",
    "#     a header (e.g. `'Date'`, `'Flight origin'`, etc.) and returns the\n",
    "#     corresponding value\n",
    "#     *Input1: accident_page (bs4.BeautifulSoup Object)\n",
    "#     *Input2: table_header text (<th>input2<th>)\n",
    "#     *Output: table_data text (<td>output<td>)\n",
    "#     '''\n",
    "\n",
    "#     if one_accident_page.find('th', text = header_name) is not None:\n",
    "#         header = one_accident_page.find('th', text = header_name)\n",
    "#         table_data = header.find_next('td').text\n",
    "#         return table_data\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# def get_all_info(a_or_b_tag):\n",
    "\n",
    "#     '''\n",
    "#     *This function gives get all the table data and append them one by one to\n",
    "#     an accidents_list\n",
    "#     *Input: `<a>` or `<b>` (Note: just input `a` or `b` without quotation marks)\n",
    "#     This input aims at getting accident name at the wiki page that list all of\n",
    "#     the accidents.\n",
    "#     *Output: [{},{},{}....], table_data wrapped by an accident_info dictionary\n",
    "#     appended one by one to an accidents_list.\n",
    "#     '''\n",
    "\n",
    "#     accident_info = {}\n",
    "#     accident_info['Date'] = get_table_data(accident_page, 'Date')\n",
    "#     accident_info['Destination'] = get_table_data(accident_page, 'Destination')\n",
    "#     accident_info['Fatalities'] = get_table_data(accident_page, 'Fatalities')\n",
    "#     accident_info['Flight origin'] = get_table_data(accident_page, 'Flight origin')\n",
    "#     accident_info['Name'] = a_or_b_tag.text\n",
    "#     accident_info['Operator'] = get_table_data(accident_page, 'Operator')\n",
    "\n",
    "#     accidents_list.append(accident_info)\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# # create an empty list for appending accident info dictionaries later\n",
    "# accidents_list = []\n",
    "\n",
    "# # some formats are <a><b> Incident </b><a>\n",
    "# for a in a_tags:\n",
    "\n",
    "#     if a.find('b') is not None:\n",
    "\n",
    "#         accident_path = a.get('href')\n",
    "#         accident_response = requests.get(base + accident_path)\n",
    "#         accident_page = bs(accident_response.text, 'html.parser')\n",
    "\n",
    "#         get_all_info(a)\n",
    "\n",
    "#         # time.sleep makes sure we are not requesting too quickly,\n",
    "#         # and thus lowers the risk of being blocked. In this case, too slow\n",
    "#         # time.sleep(2)\n",
    "\n",
    "# for b in bolds:\n",
    "\n",
    "#     if b.find('a') is not None:\n",
    "\n",
    "#         accident_path = b.find('a').get('href')\n",
    "#         accident_response = requests.get(base + accident_path)\n",
    "#         accident_page = bs(accident_response.text, 'html.parser')\n",
    "\n",
    "#         get_all_info(b)\n",
    "\n",
    "#         # time.sleep(2)\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# all_accidents_info = pd.DataFrame(accidents_list).drop_duplicates()\n",
    "# all_accidents_info.to_csv('accidents.csv', index=False)\n",
    "\n",
    "# ################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ACS Developer API Example\n",
    "# # https://api.census.gov/data/2016/acs/acs5/variables.html\n",
    "# # zcta, census tract\n",
    "# # &for=tract:*&in=state:17 (fips code)\n",
    "# ################################################################################\n",
    "\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# api = 'https://api.census.gov/data/2016/acs/acs5?'\n",
    "\n",
    "# params = {\n",
    "# 'get':'NAME,B01001_001E,B01001_026E,B02001_002E,B01002_001E,B07011_001E',\n",
    "# 'for':'county:*',\n",
    "# 'in':'state:51',\n",
    "# # in case api-key is needed:\n",
    "# # 'key':'a04219e17e382b6cd50163e0780bf67fb23341d3'\n",
    "# }\n",
    "\n",
    "# j = requests.get(api, params=params).json()\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# # <--! Data Selected from API: -->\n",
    "# # `B01001_001E`: `total population`; `B01001_026E`: `total female population`\n",
    "# # `B02001_002E`: `white population`; `B01002_001E`: `median age`\n",
    "# # `B07011_001E`: `median income (past 12 months)`\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# df = pd.DataFrame(j[1:], columns=j[0]).drop(['state', 'county'], axis=1)\n",
    "\n",
    "# df.columns = ['County/City', 'Total_Population', 'Total_Female_Population',\\\n",
    "# 'White_Population', 'Median_Age', 'Median_Income']\n",
    "\n",
    "# # create two other columns for data analysis\n",
    "# df['Female_Proportion'] = df['Total_Female_Population'].astype(float)/\\\n",
    "# df['Total_Population'].astype(float)\n",
    "# df['White_Proportion'] = df['White_Population'].astype(float)/\\\n",
    "# df['Total_Population'].astype(float)\n",
    "\n",
    "# df['County/City'] = df['County/City'].str.rstrip(', Virginia')\n",
    "\n",
    "# df.to_csv('acs.csv', index=False)\n",
    "\n",
    "# ################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Resources\n",
    "- using [plotly](https://plot.ly/python/) to create interactive web plots instead of matplotlib\n",
    "- using [django](https://www.djangoproject.com/) to make web apps in combination with your data analysis\n",
    "- [cooperating on GitHub](https://help.github.com/en/categories/collaborating-with-issues-and-pull-requests)\n",
    "    - branches\n",
    "    - pull request\n",
    "    - merge conflicts\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
