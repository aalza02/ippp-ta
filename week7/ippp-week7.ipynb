{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Internet and World Wide Web\n",
    "- The Internet is a physical network of cables and routers, and a set of protocols for moving information across that network.\n",
    "- The World Wide Web (WWW) is an information space on the Internet. It combines several concepts: \n",
    "    - Uniform Resource Locator (url) \n",
    "    - Hypertext Transfer Protocol (http) \n",
    "    - Hypertext Markup Language (html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Resource Locator\n",
    "- URLs are a system of globally unique identiﬁers for resources on the Web and elsewhere.\n",
    "- <code>scheme://host[:port]/path[?query][#fragment]</code>\n",
    "- scheme is a protcol such as http, https, etc. \n",
    "- host is something like google.com or localhost\n",
    "- :port is optional, allows a single host to have separate websites\n",
    "- path is the path to a particular resource like index.html \n",
    "- queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertext Transfer Protocol (HTTP)\n",
    "- HTTP is the core communications protocol for retrieving data \n",
    "- Consists of messages– requests and responses– sent between a client and a server\n",
    "\n",
    "![request_response](request_response.png)\n",
    "- HTTP Request\n",
    "\n",
    "![get_request](get_request.png)\n",
    "    - First line contains:\n",
    "        - HTTP method, here GET \n",
    "        - Requested URL \n",
    "        - HTTP version\n",
    "    - Rest of request may contain: \n",
    "        - User-Agent: description of the client (Used e.g. to determine whether to serve mobile website version)\n",
    "- HTTP Methods\n",
    "    - GET\n",
    "        - Most common method, used to get data\n",
    "    - POST \n",
    "        - Used to send data to server, e.g. form entries, search queries\n",
    "- HTTP Responses\n",
    "\n",
    "![response](response.png)\n",
    "    - First line contains:\n",
    "        - HTTP version\n",
    "        - HTTP response code\n",
    "    - Rest of response contains:\n",
    "        - Additional headers: Server, Content-Type, etc.\n",
    "        - Requested Content\n",
    "    - HTTP Response Codes\n",
    "        - 1xx: informational\n",
    "        - 2xx: Success\n",
    "            - 200: OK\n",
    "        - 3xx: Redirection\n",
    "            - 301: Redirect\n",
    "        - 4xx: Client Errors\n",
    "            - 404: File not found\n",
    "            - 403: Forbidden\n",
    "        - 5xx: Server Errors\n",
    "- HTTP GET Request Parameters\n",
    "\n",
    "![query](query.png)\n",
    "    - Query string with parameters sent in the URL of a GET request \n",
    "    - Parameter names and values are like a python dictionary\n",
    "    - Shouldn’t use with sensitive data (AUTH TOKEN etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertext Markup Language (HTML)\n",
    "   - [LEARN MORE ABOUT HTML](https://www.w3schools.com/html/html_intro.asp)\n",
    "   - Web browsers (Use Chrome) receive HTML documents from a web server or from local storage and render the documents into multimedia web pages. HTML describes the structure of a web page semantically and originally included cues for the appearance of the document.\n",
    "   - HTML sourcecode (View Page Source or Inspect)\n",
    "![html_source](html_source.png)\n",
    "    - HTML overview:\n",
    "        - HTML elements are the building blocks of HTML pages; HTML elements are represented by tags; HTML tags label pieces of content such as \"heading\", \"paragraph\", \"table\", and so on\n",
    "        - Most tags come in pairs (opening and closing):\n",
    "            - html\n",
    "            - div\n",
    "            - p \n",
    "            - a\n",
    "            - body\n",
    "        - Some do not (self-closing tags):\n",
    "            - img\n",
    "            - br\n",
    "        - Whitespace doesn't matter (unlike Python)\n",
    "    - Set up a basic HTML page in your text editor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Web Technologies\n",
    "- CSS\n",
    "    - .css files or code embedded in style tags\n",
    "- JavaScript\n",
    "    - .js files or code embedded in script tags\n",
    "    - browser uses the code to create dynamic content\n",
    "- Server-side languages\n",
    "    - Java, Ruby(on Rails), PHP, Python(Django), JavaScript(Node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Overview\n",
    "- Scraping is the process of programmatically extracting information from websites \n",
    "- Anything that you can view in a web browser can potentially be scraped\n",
    "- Reasons to Scrape:\n",
    "    - Some websites oﬀer services (APIs) that allow you to get data directly. So why scrape?\n",
    "        - Not all websites provide an API \n",
    "        - Not all of a website’s content is available through its API\n",
    "        - APIs often use tokens to limit the amount of data that can be requested (With scraping there is, in principle, no limit)\n",
    "- Note:\n",
    "    - Credit all sources \n",
    "        - Publishing scraped content can be a copyright violation \n",
    "    - Don’t overload websites\n",
    "        - Most sites will block you before you can do this\n",
    "    - You are not anonymous on the web\n",
    "        - Unless you take explicit steps (VPN, Tor, etc.) to do so\n",
    "    - Follow the rules of robots.txt\n",
    "- Common Web Resources:\n",
    "    - Google Maps\n",
    "    - OpenStreetMap\n",
    "    - Mapbox\n",
    "    - Twitter API\n",
    "    - American Community Survey\n",
    "    - Bureau of Labor Statistics\n",
    "    - Wikipedia tables\n",
    "    - Google Trends (No Need to Scrape)\n",
    "- Tools:\n",
    "    - [requests](https://2.python-requests.org/en/master/): Python module for retrieving web resources (mostly static) [tutorial](https://realpython.com/python-requests/#getting-started-with-requests)\n",
    "    - [beautifulsoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/): Python module for traversing and extracting elements from a web page.\n",
    "    - [pandas.read_html()](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.read_html.html): reads a well-formatted html table into a pandas DataFrame\n",
    "    - [selenium](https://selenium-python.readthedocs.io/): scrape JavaScript heavy pages with a web browser simulator\n",
    "    - [scrapy](https://docs.scrapy.org/en/latest/topics/selectors.html)\n",
    "    - regex: using the [re module](https://docs.python.org/3/library/re.html) to parse specific patterns; [good reference](https://www.tutorialspoint.com/python/python_reg_expressions.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rank</td>\n",
       "      <td>CN¥</td>\n",
       "      <td>Nominal(US$)</td>\n",
       "      <td>PPP(intl$.)</td>\n",
       "      <td>realgrowth(%)</td>\n",
       "      <td>Share(%)</td>\n",
       "      <td>Rank</td>\n",
       "      <td>CN¥</td>\n",
       "      <td>Nominal(US$)</td>\n",
       "      <td>PPP(intl$.)</td>\n",
       "      <td>Share(%)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82712.20</td>\n",
       "      <td>12250.39</td>\n",
       "      <td>23589.60</td>\n",
       "      <td>6.9</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59660</td>\n",
       "      <td>8836</td>\n",
       "      <td>17015</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1386395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>1</td>\n",
       "      <td>8987.92</td>\n",
       "      <td>1331.19</td>\n",
       "      <td>2563.36</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.87</td>\n",
       "      <td>8</td>\n",
       "      <td>81089</td>\n",
       "      <td>12010</td>\n",
       "      <td>23127</td>\n",
       "      <td>136.0</td>\n",
       "      <td>109240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jiangsu</td>\n",
       "      <td>2</td>\n",
       "      <td>8590.09</td>\n",
       "      <td>1272.27</td>\n",
       "      <td>2449.90</td>\n",
       "      <td>7.2</td>\n",
       "      <td>10.39</td>\n",
       "      <td>4</td>\n",
       "      <td>107189</td>\n",
       "      <td>17176</td>\n",
       "      <td>32570</td>\n",
       "      <td>180.0</td>\n",
       "      <td>79875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shandong</td>\n",
       "      <td>3</td>\n",
       "      <td>7267.82</td>\n",
       "      <td>1076.43</td>\n",
       "      <td>2072.79</td>\n",
       "      <td>7.4</td>\n",
       "      <td>8.79</td>\n",
       "      <td>9</td>\n",
       "      <td>72851</td>\n",
       "      <td>10790</td>\n",
       "      <td>20777</td>\n",
       "      <td>122.0</td>\n",
       "      <td>99470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zhejiang</td>\n",
       "      <td>4</td>\n",
       "      <td>5176.83</td>\n",
       "      <td>766.73</td>\n",
       "      <td>1476.44</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.26</td>\n",
       "      <td>5</td>\n",
       "      <td>92057</td>\n",
       "      <td>13634</td>\n",
       "      <td>26255</td>\n",
       "      <td>154.0</td>\n",
       "      <td>55645.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Henan</td>\n",
       "      <td>5</td>\n",
       "      <td>4498.82</td>\n",
       "      <td>666.31</td>\n",
       "      <td>1283.07</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.44</td>\n",
       "      <td>19</td>\n",
       "      <td>47129</td>\n",
       "      <td>6980</td>\n",
       "      <td>13441</td>\n",
       "      <td>79.0</td>\n",
       "      <td>95062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sichuan</td>\n",
       "      <td>6</td>\n",
       "      <td>3698.02</td>\n",
       "      <td>547.71</td>\n",
       "      <td>1054.68</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.47</td>\n",
       "      <td>22</td>\n",
       "      <td>44651</td>\n",
       "      <td>6613</td>\n",
       "      <td>12735</td>\n",
       "      <td>75.0</td>\n",
       "      <td>82330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hubei</td>\n",
       "      <td>7</td>\n",
       "      <td>3652.30</td>\n",
       "      <td>540.94</td>\n",
       "      <td>1041.64</td>\n",
       "      <td>7.8</td>\n",
       "      <td>4.42</td>\n",
       "      <td>11</td>\n",
       "      <td>61971</td>\n",
       "      <td>9179</td>\n",
       "      <td>17674</td>\n",
       "      <td>104.0</td>\n",
       "      <td>58685.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hebei</td>\n",
       "      <td>8</td>\n",
       "      <td>3596.40</td>\n",
       "      <td>532.66</td>\n",
       "      <td>1025.70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>4.35</td>\n",
       "      <td>18</td>\n",
       "      <td>47985</td>\n",
       "      <td>7107</td>\n",
       "      <td>13685</td>\n",
       "      <td>80.0</td>\n",
       "      <td>74475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hunan</td>\n",
       "      <td>9</td>\n",
       "      <td>3459.06</td>\n",
       "      <td>512.32</td>\n",
       "      <td>986.53</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.18</td>\n",
       "      <td>16</td>\n",
       "      <td>50563</td>\n",
       "      <td>7489</td>\n",
       "      <td>14421</td>\n",
       "      <td>85.0</td>\n",
       "      <td>68025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>10</td>\n",
       "      <td>3229.83</td>\n",
       "      <td>478.37</td>\n",
       "      <td>921.15</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3.90</td>\n",
       "      <td>6</td>\n",
       "      <td>82976</td>\n",
       "      <td>12289</td>\n",
       "      <td>23665</td>\n",
       "      <td>139.0</td>\n",
       "      <td>38565.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1             2            3              4         5      6   \\\n",
       "0        Rank  CN¥  Nominal(US$)  PPP(intl$.)  realgrowth(%)  Share(%)   Rank   \n",
       "1       China  NaN      82712.20     12250.39       23589.60       6.9    100   \n",
       "2   Guangdong    1       8987.92      1331.19        2563.36       7.5  10.87   \n",
       "3     Jiangsu    2       8590.09      1272.27        2449.90       7.2  10.39   \n",
       "4    Shandong    3       7267.82      1076.43        2072.79       7.4   8.79   \n",
       "5    Zhejiang    4       5176.83       766.73        1476.44       7.8   6.26   \n",
       "6       Henan    5       4498.82       666.31        1283.07       7.8   5.44   \n",
       "7     Sichuan    6       3698.02       547.71        1054.68       8.1   4.47   \n",
       "8       Hubei    7       3652.30       540.94        1041.64       7.8   4.42   \n",
       "9       Hebei    8       3596.40       532.66        1025.70       6.7   4.35   \n",
       "10      Hunan    9       3459.06       512.32         986.53       8.0   4.18   \n",
       "11     Fujian   10       3229.83       478.37         921.15       8.1   3.90   \n",
       "\n",
       "     7             8            9         10     11         12  \n",
       "0   CN¥  Nominal(US$)  PPP(intl$.)  Share(%)    NaN        NaN  \n",
       "1   NaN         59660         8836     17015  100.0  1386395.0  \n",
       "2     8         81089        12010     23127  136.0   109240.0  \n",
       "3     4        107189        17176     32570  180.0    79875.0  \n",
       "4     9         72851        10790     20777  122.0    99470.0  \n",
       "5     5         92057        13634     26255  154.0    55645.0  \n",
       "6    19         47129         6980     13441   79.0    95062.0  \n",
       "7    22         44651         6613     12735   75.0    82330.0  \n",
       "8    11         61971         9179     17674  104.0    58685.0  \n",
       "9    18         47985         7107     13685   80.0    74475.0  \n",
       "10   16         50563         7489     14421   85.0    68025.0  \n",
       "11    6         82976        12289     23665  139.0    38565.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read html tables\n",
    "import pandas as pd\n",
    "pd.read_html(\"https://en.wikipedia.org/wiki/Economy_of_China\", skiprows=2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Wikipedia Scrape Example:\n",
    "# # https://en.wikipedia.org//wiki/List_of_accidents_and_incidents_involving_commercial_aircraft\n",
    "# ################################################################################\n",
    "\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# # whether to import time based on whether initiate time.sleep()\n",
    "# # import time\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# base = 'https://en.wikipedia.org'\n",
    "# path = '/wiki/List_of_accidents_and_incidents_involving_commercial_aircraft'\n",
    "# response = requests.get(base + path)\n",
    "# page = bs(response.text, 'html.parser')\n",
    "# bolds = page.find_all('b')[:-1]\n",
    "# a_tags = page.find_all('a')\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# def get_table_data(one_accident_page, header_name):\n",
    "\n",
    "#     '''\n",
    "#     *This function takes as its argument an accident page and the name of\n",
    "#     a header (e.g. `'Date'`, `'Flight origin'`, etc.) and returns the\n",
    "#     corresponding value\n",
    "#     *Input1: accident_page (bs4.BeautifulSoup Object)\n",
    "#     *Input2: table_header text (<th>input2<th>)\n",
    "#     *Output: table_data text (<td>output<td>)\n",
    "#     '''\n",
    "\n",
    "#     if one_accident_page.find('th', text = header_name) is not None:\n",
    "#         header = one_accident_page.find('th', text = header_name)\n",
    "#         table_data = header.find_next('td').text\n",
    "#         return table_data\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# def get_all_info(a_or_b_tag):\n",
    "\n",
    "#     '''\n",
    "#     *This function gives get all the table data and append them one by one to\n",
    "#     an accidents_list\n",
    "#     *Input: `<a>` or `<b>` (Note: just input `a` or `b` without quotation marks)\n",
    "#     This input aims at getting accident name at the wiki page that list all of\n",
    "#     the accidents.\n",
    "#     *Output: [{},{},{}....], table_data wrapped by an accident_info dictionary\n",
    "#     appended one by one to an accidents_list.\n",
    "#     '''\n",
    "\n",
    "#     accident_info = {}\n",
    "#     accident_info['Date'] = get_table_data(accident_page, 'Date')\n",
    "#     accident_info['Destination'] = get_table_data(accident_page, 'Destination')\n",
    "#     accident_info['Fatalities'] = get_table_data(accident_page, 'Fatalities')\n",
    "#     accident_info['Flight origin'] = get_table_data(accident_page, 'Flight origin')\n",
    "#     accident_info['Name'] = a_or_b_tag.text\n",
    "#     accident_info['Operator'] = get_table_data(accident_page, 'Operator')\n",
    "\n",
    "#     accidents_list.append(accident_info)\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# # create an empty list for appending accident info dictionaries later\n",
    "# accidents_list = []\n",
    "\n",
    "# # some formats are <a><b> Incident </b><a>\n",
    "# for a in a_tags:\n",
    "\n",
    "#     if a.find('b') is not None:\n",
    "\n",
    "#         accident_path = a.get('href')\n",
    "#         accident_response = requests.get(base + accident_path)\n",
    "#         accident_page = bs(accident_response.text, 'html.parser')\n",
    "\n",
    "#         get_all_info(a)\n",
    "\n",
    "#         # time.sleep makes sure we are not requesting too quickly,\n",
    "#         # and thus lowers the risk of being blocked. In this case, too slow\n",
    "#         # time.sleep(2)\n",
    "\n",
    "# for b in bolds:\n",
    "\n",
    "#     if b.find('a') is not None:\n",
    "\n",
    "#         accident_path = b.find('a').get('href')\n",
    "#         accident_response = requests.get(base + accident_path)\n",
    "#         accident_page = bs(accident_response.text, 'html.parser')\n",
    "\n",
    "#         get_all_info(b)\n",
    "\n",
    "#         # time.sleep(2)\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# all_accidents_info = pd.DataFrame(accidents_list).drop_duplicates()\n",
    "# all_accidents_info.to_csv('accidents.csv', index=False)\n",
    "\n",
    "# ################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ACS Developer API Example\n",
    "# # https://api.census.gov/data/2016/acs/acs5/variables.html\n",
    "# # zcta, census tract\n",
    "# # &for=tract:*&in=state:17 (fips code)\n",
    "# ################################################################################\n",
    "\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# api = 'https://api.census.gov/data/2016/acs/acs5?'\n",
    "\n",
    "# params = {\n",
    "# 'get':'NAME,B01001_001E,B01001_026E,B02001_002E,B01002_001E,B07011_001E',\n",
    "# 'for':'county:*',\n",
    "# 'in':'state:51',\n",
    "# # in case api-key is needed:\n",
    "# # 'key':'a04219e17e382b6cd50163e0780bf67fb23341d3'\n",
    "# }\n",
    "\n",
    "# j = requests.get(api, params=params).json()\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# # <--! Data Selected from API: -->\n",
    "# # `B01001_001E`: `total population`; `B01001_026E`: `total female population`\n",
    "# # `B02001_002E`: `white population`; `B01002_001E`: `median age`\n",
    "# # `B07011_001E`: `median income (past 12 months)`\n",
    "\n",
    "# ################################################################################\n",
    "\n",
    "# df = pd.DataFrame(j[1:], columns=j[0]).drop(['state', 'county'], axis=1)\n",
    "\n",
    "# df.columns = ['County/City', 'Total_Population', 'Total_Female_Population',\\\n",
    "# 'White_Population', 'Median_Age', 'Median_Income']\n",
    "\n",
    "# # create two other columns for data analysis\n",
    "# df['Female_Proportion'] = df['Total_Female_Population'].astype(float)/\\\n",
    "# df['Total_Population'].astype(float)\n",
    "# df['White_Proportion'] = df['White_Population'].astype(float)/\\\n",
    "# df['Total_Population'].astype(float)\n",
    "\n",
    "# df['County/City'] = df['County/City'].str.rstrip(', Virginia')\n",
    "\n",
    "# df.to_csv('acs.csv', index=False)\n",
    "\n",
    "# ################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Resources\n",
    "- using [plotly](https://plot.ly/python/) to create interactive web plots instead of matplotlib\n",
    "- using [django](https://www.djangoproject.com/) to make web apps in combination with your data analysis\n",
    "- [cooperating on GitHub](https://help.github.com/en/categories/collaborating-with-issues-and-pull-requests)\n",
    "    - branches\n",
    "    - pull request\n",
    "    - merge conflicts\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
